{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['martes', 'de', 'muchas', 'hoy', 'es', 'dia', 'el', 'gracias', 'que']\n"]}],"source":["import numpy as np\n","\n","corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","documentos = [documento.split() for documento in corpus]\n","\n","vocabulario = list(set([termino for documento in documentos for termino in documento]))\n","print(documentos)\n","print(vocabulario)\n"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulario:\n","['martes', 'de', 'muchas', 'hoy', 'es', 'dia', 'el', 'gracias', 'que']\n","Matriz One-Hot Encoding:\n","[[0 0 0 1 1 1 0 0 1]\n"," [1 1 0 1 1 1 1 0 0]\n"," [1 0 1 0 0 0 0 1 0]]\n"]}],"source":["textos = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","vocabulario = list(set(word for texto in textos for word in texto.split()))\n","matriz_one_hot = np.zeros((len(textos), len(vocabulario)), dtype=int)\n","\n","for i, texto in enumerate(textos):\n","    for j, palabra in enumerate(vocabulario):\n","        matriz_one_hot[i, j] = 1 if palabra in texto.split() else 0\n","\n","print(\"Vocabulario:\")\n","print(vocabulario)\n","print(\"Matriz One-Hot Encoding:\")\n","print(matriz_one_hot)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulario:\n","['martes', 'de', 'muchas', 'hoy', 'es', 'dia', 'el', 'gracias', 'que']\n","Matriz de frecuencia de términos:\n","[[0 0 0 1 1 1 0 0 1]\n"," [2 1 0 1 1 1 1 0 0]\n"," [1 0 1 0 0 0 0 1 0]]\n"]}],"source":["textos = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","\n","vocabulario = list(set(word.lower() for texto in textos for word in texto.split()))\n","\n","matriz_frecuencia = np.zeros((len(textos), len(vocabulario)), dtype=int)\n","\n","for i, texto in enumerate(textos):\n","    for j, palabra in enumerate(vocabulario):\n","        matriz_frecuencia[i, j] = texto.lower().split().count(palabra)\n","\n","print('Vocabulario:')\n","print(vocabulario)\n","print('Matriz de frecuencia de términos:')\n","print(matriz_frecuencia)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulario:\n","['martes', 'de', 'muchas', 'hoy', 'es', 'dia', 'el', 'gracias', 'que']\n","Matriz TF-IDF:\n","[0.0, 0.0, 0.0, 0.17609125905568124, 0.17609125905568124, 0.17609125905568124, 0.0, 0.0, 0.47712125471966244]\n","[0.3521825181113625, 0.47712125471966244, 0.0, 0.17609125905568124, 0.17609125905568124, 0.17609125905568124, 0.47712125471966244, 0.0, 0.0]\n","[0.17609125905568124, 0.0, 0.47712125471966244, 0.0, 0.0, 0.0, 0.0, 0.47712125471966244, 0.0]\n"]}],"source":["import math\n","\n","textos = ['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n","\n","vocabulario = list(set(word for texto in textos for word in texto.split()))\n","\n","n_documentos = len(textos)\n","\n","idf = {}\n","\n","for palabra in vocabulario:\n","    documentos_con_termino = sum(1 for texto in textos if palabra in texto.split())\n","    idf[palabra] = math.log10(n_documentos / documentos_con_termino)\n","\n","matriz_tfidf = []\n","\n","for texto in textos:\n","    tfidf_documento = []\n","    for palabra in vocabulario:\n","        tf = texto.split().count(palabra)\n","        tfidf = tf * idf[palabra]\n","        tfidf_documento.append(tfidf)\n","    matriz_tfidf.append(tfidf_documento)\n","\n","print(\"Vocabulario:\")\n","print(vocabulario)\n","\n","print(\"Matriz TF-IDF:\")\n","for fila in matriz_tfidf:\n","    print(fila)\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ordenado por similitud coseno usando TF-IDF:\n","[1 0 2]\n","Ordenado por similitud coseno usando One-Hot Encoding:\n","[1 0 2]\n","Ordenado por similitud coseno usando vectores de frecuencia:\n","[1 0 2]\n"]}],"source":["import numpy as np\n","\n","def cosine_similarity(v1, v2):\n","    dot_product = np.dot(v1, v2)\n","    norm_v1 = np.linalg.norm(v1)\n","    norm_v2 = np.linalg.norm(v2)\n","    \n","    if norm_v1 == 0 or norm_v2 == 0:\n","        return 0.0\n","    \n","    return dot_product / (norm_v1 * norm_v2)\n","\n","def ordenar_por_similitud_coseno(df, ref_doc_index):\n","    n_docs = df.shape[0]\n","    similitudes = np.zeros(shape=(n_docs,))\n","    v1 = df[ref_doc_index, :] \n","    \n","    for other_doc_idx in range(n_docs):\n","        v2 = df[other_doc_idx, :]  \n","        similitudes[other_doc_idx] = cosine_similarity(v1, v2)\n","    \n","   \n","    return np.argsort(-similitudes)\n","\n","matriz_tfidf = np.array(matriz_tfidf)\n","matriz_one_hot = np.array(matriz_one_hot)\n","matriz_frecuencia = np.array(matriz_frecuencia)\n","\n","print(\"Ordenado por similitud coseno usando TF-IDF:\")\n","print(ordenar_por_similitud_coseno(matriz_tfidf, 1)) \n","\n","print(\"Ordenado por similitud coseno usando One-Hot Encoding:\")\n","print(ordenar_por_similitud_coseno(matriz_one_hot, 1))  \n","\n","print(\"Ordenado por similitud coseno usando vectores de frecuencia:\")\n","print(ordenar_por_similitud_coseno(matriz_frecuencia, 1)) \n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
